{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import pywhatkit\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=100\n",
    "while True:\n",
    "    ret,photo = cam.read()\n",
    "    faces = model1.detectMultiScale(photo)\n",
    "    if len(faces) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        photo_cropped = cropper(photo)\n",
    "        cv2.resize(photo_cropped,(200,200))\n",
    "        cv2.imwrite(\"./faces/harsh/\" +str(count)+\".jpg\",photo_cropped)\n",
    "        count+=1\n",
    "        \n",
    "        if cv2.waitKey(1) == 13 or count == 200:\n",
    "            break\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropper(img):\n",
    "    for (x1,y1,x2,y2) in faces:\n",
    "        cropped = img[y1:y1+y2,x1:x1+x2]\n",
    "        return cropped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data, labels = ([],[])\n",
    "\n",
    "path = \"./faces/harsh/\"\n",
    "location = [f for f in listdir(path) if isfile(join(path,f))]\n",
    "for i,files in enumerate(location):\n",
    "    image_path = path + location[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE )\n",
    "    training_data.append(np.asarray(images, dtype=np.uint8))\n",
    "    labels.append(i)\n",
    "\n",
    "labels = np.asarray(labels,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face_LBPHFaceRecognizer.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(np.asarray(training_data),np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,photo = cam.read()\n",
    "    photo = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = model1.detectMultiScale(photo)\n",
    "    if len(faces) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        x1,y1,x2,y2 = faces[0]\n",
    "        square = cv2.rectangle(photo,(x1,y1),(x1+x2,y1+y2),[0,0,255],1)\n",
    "        cv2.imshow('Camera', square)\n",
    "        predict_photo = cropper(photo)\n",
    "        x = model.predict(predict_photo)\n",
    "        con = int(100 * (1 - (x[1])/400))\n",
    "\n",
    "        if con>90:\n",
    "            if x[0]<100:\n",
    "                cv2.putText(square, str(con), (100,120), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0))\n",
    "                    pywhatkit.sendwhatmsg_instantly(phone_number,message_string)\n",
    "            elif x[0]>100 and x[0]<200:\n",
    "                cv2.putText(square, str(con), (100,120), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255))\n",
    "                ec2  = os.popen(\"aws ec2 run-instances --image-id ami-0e5d82cae7458738b --instance-type t2.micro --count 1 --subnet-id subnet-1311e478 --security-group-ids sg-029e99a703a4fa089 --key-name AWS_key\").read()\n",
    "                ec2 = json.loads(ec2)\n",
    "                ec2_id = ec2['Instances'][0]['InstanceId']\n",
    "                gp = os.popen(\"aws ec2 create-volume --volume-type gp2 --size 5 --availability-zone ap-south-1a\").read()\n",
    "                gp = json.loads(gp)\n",
    "                gp = gp['VolumeId']\n",
    "                final = \"aws ec2 attach-volume --volume-id \"+ gp +\" --instance-id \"+ ec2_id +\" --device /dev/sdf\"\n",
    "                os.system(final)\n",
    "            \n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break   \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
